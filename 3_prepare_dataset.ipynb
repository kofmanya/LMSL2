{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "a250ab0c-e72c-4b0e-a6c0-92748484d8ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle\n",
    "import pandas as pd\n",
    "import shutil\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "379203e6-9412-4b59-88c8-d564d725fac1",
   "metadata": {},
   "outputs": [],
   "source": [
    "downloaded_items_path = '/Users/kofmanya/Desktop/HSE/My assignments/Diploma/Dataset/downloaded_items.pkl'\n",
    "items_path = '/Users/kofmanya/Desktop/HSE/My assignments/Diploma/Dataset/items.pkl'\n",
    "images_path = '/Users/kofmanya/Desktop/HSE/My assignments/Diploma/Dataset/images'\n",
    "dest_path = '/Users/kofmanya/Desktop/HSE/My assignments/year 2/LMSL2/Final_SGA/zalando/images'\n",
    "\n",
    "with open(downloaded_items_path, 'rb') as file:\n",
    "    saved_items = pickle.load(file)\n",
    "\n",
    "with open(items_path, 'rb') as file:\n",
    "    items = pickle.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "bccecb5a-de74-4b43-a608-e03d0c701927",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloaded: 1000 damenbekleidung-kleider\n",
      "Downloaded: 1000 damenbekleidung-shirts\n",
      "Downloaded: 1000 damenbekleidung-jeans\n",
      "Downloaded: 1000 damenbekleidung-jacken\n",
      "Downloaded: 1000 damenbekleidung-jacken-maentel\n",
      "Downloaded: 1000 damenbekleidung-blusen-tuniken\n"
     ]
    }
   ],
   "source": [
    "for item in saved_items.keys():\n",
    "    print(f\"Downloaded: {len(saved_items[item])} {item}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "07a0ecf8-e456-479f-9af7-818e21506e2f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saint-tropez-freizeitkleid-night-sky-s2821c0op-k11\n"
     ]
    }
   ],
   "source": [
    "first_key = next(iter(saved_items.keys()))\n",
    "print(saved_items[first_key][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fade0c61-c042-4154-bca9-8013c2f87ec3",
   "metadata": {},
   "outputs": [],
   "source": [
    "first_key = next(iter(items.keys()))\n",
    "print(items[first_key])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "20774078-b7f0-4345-bb3e-390411a57e1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#classes = ['dresses', 'tshirts_and_tops', 'jeans', 'jackets_and_blazers', 'coats', 'shirts_and_blouses']\n",
    "\n",
    "classes_dict = {\n",
    "    'damenbekleidung-kleider': 'dresses',\n",
    "    'damenbekleidung-shirts': 'tshirts_and_tops',\n",
    "    'damenbekleidung-jeans': 'jeans',\n",
    "    'damenbekleidung-jacken': 'jackets_and_blazers',\n",
    "    'damenbekleidung-jacken-maentel': 'coats',\n",
    "    'damenbekleidung-blusen-tuniken': 'shirts_and_blouses'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "86e4c4cb-3ad2-4202-a53c-4e5757b852a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error copying /Users/kofmanya/Desktop/HSE/My assignments/Diploma/Dataset/images/spp-media-p1/e171a82209c8410ab4a9c3e67e4ebd35/60f40c9649504eee9c31e47416c3df28.jpg to /Users/kofmanya/Desktop/HSE/My assignments/year 2/LMSL2/Final_SGA/zalando/images/jackets_and_blazers: [Errno 60] Operation timed out: '/Users/kofmanya/Desktop/HSE/My assignments/Diploma/Dataset/images/spp-media-p1/e171a82209c8410ab4a9c3e67e4ebd35/60f40c9649504eee9c31e47416c3df28.jpg' -> '/Users/kofmanya/Desktop/HSE/My assignments/year 2/LMSL2/Final_SGA/zalando/images/jackets_and_blazers/60f40c9649504eee9c31e47416c3df28.jpg'\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import shutil\n",
    "\n",
    "MAX_FILES_PER_CATEGORY = 1020\n",
    "\n",
    "for item in items.values():\n",
    "    if item['id'] in saved_items[item['category']]:\n",
    "        category = classes_dict[item['category']]\n",
    "        dest = f\"{dest_path}/{category}\"\n",
    "\n",
    "        os.makedirs(dest, exist_ok=True)\n",
    "\n",
    "        files = {f for f in os.listdir(dest) if os.path.isfile(os.path.join(dest, f))}  \n",
    "        current_file_count = len(files)\n",
    "\n",
    "        if current_file_count >= MAX_FILES_PER_CATEGORY:\n",
    "            continue\n",
    "\n",
    "        for image in item['images']:\n",
    "            filename = image.split('/')[-1]\n",
    "            image_name = image.replace('https://img01.ztat.net/article/', '')\n",
    "            \n",
    "            if image_name not in files:\n",
    "                src = f\"{images_path}/{image_name}\"\n",
    "                dest_file_path = f\"{dest}/{filename}\"\n",
    "\n",
    "                if os.path.isfile(src):\n",
    "                    src_size = os.path.getsize(src)\n",
    "                    if src_size == 0:\n",
    "                        continue\n",
    "                        \n",
    "                    try:\n",
    "                        shutil.copy(src, dest)\n",
    "                        dest_size = os.path.getsize(dest_file_path)\n",
    "    \n",
    "                        if src_size != dest_size:\n",
    "                            print(f\"File size mismatch: {src} -> {dest_file_path}\")\n",
    "                        else:\n",
    "                            files.add(image_name)\n",
    "                            current_file_count += 1\n",
    "                    except Exception as e:\n",
    "                        print(f\"Error copying {src} to {dest}: {e}\")\n",
    "                        os.remove(dest_file_path)\n",
    "            if current_file_count >= MAX_FILES_PER_CATEGORY:\n",
    "                break\n",
    "\n",
    "MAX_FILES_PER_CATEGORY = 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "e4f619f1-40b8-45a2-ac1c-e5ed7ac7af4c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Removed: /Users/kofmanya/Desktop/HSE/My assignments/year 2/LMSL2/Final_SGA/.DS_Store\n",
      "Removed: /Users/kofmanya/Desktop/HSE/My assignments/year 2/LMSL2/Final_SGA/data/.DS_Store\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "def remove_ds_store(directory):\n",
    "    for root, _, files in os.walk(directory):\n",
    "        for file in files:\n",
    "            if file == '.DS_Store':\n",
    "                file_path = os.path.join(root, file)\n",
    "                try:\n",
    "                    os.remove(file_path)\n",
    "                    print(f\"Removed: {file_path}\")\n",
    "                except Exception as e:\n",
    "                    print(f\"Error removing {file_path}: {e}\")\n",
    "\n",
    "# Specify the root directory where you want to remove .DS_Store files\n",
    "root_directory = \"/Users/kofmanya/Desktop/HSE/My assignments/year 2/LMSL2/Final_SGA/\"\n",
    "remove_ds_store(root_directory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "e9d818f2-ce99-4f74-8894-a0cc6b470d7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "for dir in os.listdir(dest_path):\n",
    "    full_path = os.path.join(dest_path, dir)\n",
    "    if os.path.isdir(full_path):\n",
    "        files = [f for f in os.listdir(full_path)]\n",
    "        for file in files[MAX_FILES_PER_CATEGORY:]:\n",
    "            file_path = os.path.join(full_path, file)\n",
    "            try:\n",
    "                os.remove(file_path)\n",
    "            except Exception as e:\n",
    "                print(f'Error deleting {file}: {e}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "e059571f-b935-493e-9e85-be11aa84217d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000\n",
      "1000\n",
      "1000\n",
      "1000\n",
      "1000\n",
      "1000\n"
     ]
    }
   ],
   "source": [
    "for dir in os.listdir(dest_path):\n",
    "    full_path = os.path.join(dest_path, dir)\n",
    "    if os.path.isdir(full_path):\n",
    "        files = [f for f in os.listdir(full_path)]\n",
    "        print(len(files))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "c6e89f02-1579-402a-afc2-fbe7a77f376f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'coats': [], 'jackets_and_blazers': [], 'jeans': [], 'dresses': [], 'shirts_and_blouses': [], 'tshirts_and_tops': []}\n",
      "{'coats': [], 'jackets_and_blazers': [], 'jeans': [], 'dresses': [], 'shirts_and_blouses': [], 'tshirts_and_tops': []}\n"
     ]
    }
   ],
   "source": [
    "meta_path = \"/Users/kofmanya/Desktop/HSE/My assignments/year 2/LMSL2/Final_SGA/zalando/meta\"\n",
    "\n",
    "os.makedirs(meta_path, exist_ok=True)\n",
    "\n",
    "train_txt = os.path.join(meta_path, \"train.txt\")\n",
    "test_txt = os.path.join(meta_path, \"test.txt\")\n",
    "train_json = os.path.join(meta_path, \"train.json\")\n",
    "test_json = os.path.join(meta_path, \"test.json\")\n",
    "\n",
    "train_data = {}\n",
    "test_data = {}\n",
    "\n",
    "for dir in os.listdir(dest_path):\n",
    "    full_path = os.path.join(dest_path, dir)\n",
    "    if os.path.isdir(full_path):\n",
    "        train_data[dir] = []\n",
    "        test_data[dir] = []\n",
    "\n",
    "print(train_data)\n",
    "print(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "95c7b933-67bc-4dc6-b239-e32926ef94e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classes written to /Users/kofmanya/Desktop/HSE/My assignments/year 2/LMSL2/Final_SGA/zalando/meta/classes.txt\n",
      "Labels written to /Users/kofmanya/Desktop/HSE/My assignments/year 2/LMSL2/Final_SGA/zalando/meta/labels.txt\n"
     ]
    }
   ],
   "source": [
    "classes_txt = os.path.join(meta_path, \"classes.txt\")\n",
    "labels_txt = os.path.join(meta_path, \"labels.txt\")\n",
    "\n",
    "classes = ['coats', 'dresses', 'jackets_and_blazers', 'jeans', 'shirts_and_blouses', 'tshirts_and_tops']\n",
    "labels = ['Coats', 'Dresses', 'Jackets_and_blazers', 'Jeans', 'Shirts_and_blouses', 'Tshirts_and_tops']\n",
    "\n",
    "with open(classes_txt, 'w') as f:\n",
    "    for class_name in classes:\n",
    "        f.write(class_name + '\\n')\n",
    "\n",
    "with open(labels_txt, 'w') as f:\n",
    "    for label in labels:\n",
    "        f.write(label + '\\n')\n",
    "\n",
    "print(f\"Classes written to {classes_txt}\")\n",
    "print(f\"Labels written to {labels_txt}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "8c801edb-cfe2-4c8f-bc66-bc96d459c87f",
   "metadata": {},
   "outputs": [],
   "source": [
    "SEPARATE_INDEX = int(MAX_FILES_PER_CATEGORY * 0.75)\n",
    "\n",
    "with open(train_txt, 'w') as train_file, open(test_txt, 'w') as test_file:\n",
    "    for dir in os.listdir(dest_path):\n",
    "        full_path = os.path.join(dest_path, dir)\n",
    "        if os.path.isdir(full_path):\n",
    "            files = [f for f in os.listdir(full_path)]\n",
    "            for file in files[:SEPARATE_INDEX]:\n",
    "                path = os.path.join(dir, file)\n",
    "                train_file.write(path + \"\\n\")\n",
    "                train_data[dir].append(path)\n",
    "            for file in files[SEPARATE_INDEX:]:\n",
    "                path = os.path.join(dir, file)\n",
    "                test_file.write(path + \"\\n\")\n",
    "                test_data[dir].append(path)\n",
    "\n",
    "with open(train_json, 'w') as train_json_file:\n",
    "    json.dump(train_data, train_json_file, indent=4)\n",
    "\n",
    "with open(test_json, 'w') as test_json_file:\n",
    "    json.dump(test_data, test_json_file, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "98e4f8a2-2b10-4558-b1cc-f11adb985623",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The file /Users/kofmanya/Desktop/HSE/My assignments/year 2/LMSL2/Final_SGA/zalando/meta/train.txt contains 4500 lines.\n",
      "The file /Users/kofmanya/Desktop/HSE/My assignments/year 2/LMSL2/Final_SGA/zalando/meta/test.txt contains 1500 lines.\n"
     ]
    }
   ],
   "source": [
    "with open(train_txt, 'r') as file:\n",
    "    line_count_train = sum(1 for line in file)\n",
    "\n",
    "print(f\"The file {train_txt} contains {line_count_train} lines.\")\n",
    "\n",
    "with open(test_txt, 'r') as file:\n",
    "    line_count_test = sum(1 for line in file)\n",
    "\n",
    "print(f\"The file {test_txt} contains {line_count_test} lines.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01ff6174-c8ad-4043-baa0-ef85d9f3fe25",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
